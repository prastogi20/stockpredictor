{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c96163-d872-496e-a5d0-f20b23a91e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib as plot\n",
    "\n",
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccbe9ec-d05f-45f1-b9fa-dcdd09c8e733",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run PrepareData.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305bfd3a-36dc-4b41-9998-7305b811e7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tsla_stock_values_df.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cab05c0-cb37-4761-af85-0c059102282b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create daily_return column\n",
    "df['daily_return']= df['close_value'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b3bc8e-d174-4351-8fcd-31d647ae46d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up new column 'price_direction', where 0 if 'daily_return' < 0, \n",
    "#and 1 if 'daily_return' > 0. \n",
    "df['price_direction']= 0\n",
    "df.loc[df['daily_return'] >= 0, 'price_direction'] =1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa22ec1-be91-4957-84e1-99bae6de7e72",
   "metadata": {},
   "source": [
    "## Adding technical indicators to TSLA dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4721a10e-1f9f-4ff9-b5d3-7e6169ef91ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_ta as ta\n",
    "\n",
    "# Calculate MACD values using the pandas_ta library\n",
    "df.ta.macd(close='close_value', fast=12, slow=26, signal=9, append=True)\n",
    "\n",
    "# Calculate High-Low Percentage values using the pandas_ta library\n",
    "df['HL_PCT'] = (df['high_value'] - df['low_value']) / df['close_value'] * 100.0\n",
    "\n",
    "# Calculate RSI values using the pandas_ta library\n",
    "df['RSI'] = df.ta.rsi(close= 'close_value', length= 14, scalar= 100)\n",
    "\n",
    "# Calculate VPT values using the pandas_ta library\n",
    "df['PVT'] = df.ta.pvt(close= 'close_value',volume= 'volume',drift= 1)\n",
    "\n",
    "# Clean Nan\n",
    "df= df.dropna()\n",
    "\n",
    "# View result\n",
    "display(df.head())\n",
    "display(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44d429e-cbae-4533-8209-342bc914b6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['daily_return','volume','open_value','high_value','low_value'],\n",
    "           axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e015f86-4a4b-410c-a5fc-f207e909149a",
   "metadata": {},
   "source": [
    "## Create train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c18c7b-0504-4923-8dde-09f831c7c2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data into labels and features\n",
    "\n",
    "# Separate the y variable, the labels\n",
    "y= df['price_direction']\n",
    "\n",
    "# Separate the X variable, the features\n",
    "X= df.drop('price_direction', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8062962-119c-4817-b4e7-3e9ca09f4b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5f4b90-c63a-4e79-9343-58d2e04067fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeb047b-634d-4e33-9118-4dcbe2fc99d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the balance of our target values\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16369d35-08af-43f1-8b89-2b4f46b66cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.offsets import DateOffset\n",
    "# Select the start of the training period\n",
    "training_begin = X.index.min()\n",
    "\n",
    "# Display the training begin date\n",
    "print(training_begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d766855-19c5-4e81-b4db-327ac0cc4fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the ending period for the training data with an offset of 3 months\n",
    "training_end = X.index.min() + DateOffset(months=3)\n",
    "\n",
    "# Display the training end date\n",
    "print(training_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83f89c8-959d-4181-94b4-d556ef837b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the X_train and y_train DataFrames\n",
    "X_train = X.loc[training_begin:training_end]\n",
    "y_train = y.loc[training_begin:training_end]\n",
    "\n",
    "# Review the X_train DataFrame\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb720fd8-9601-4aa9-924f-05e474774d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the X_test and y_test DataFrames\n",
    "X_test = X.loc[training_end+DateOffset(hours=1):]\n",
    "y_test = y.loc[training_end+DateOffset(hours=1):]\n",
    "\n",
    "# Review the X_test DataFrame\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e64d01c-ca79-4a0c-91db-2228d4c4c44b",
   "metadata": {},
   "source": [
    "## Using ML model to predict price movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42cf656-087d-412d-997c-9802d336f7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Creating StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "# Fitting Standard Scaller\n",
    "X_scaler = scaler.fit(X_train)\n",
    "# Scaling data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1c5043-6e85-4816-afad-31debd8e7cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011b9056-bd36-4410-afff-76ddb825e5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Create a random forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=500, random_state=1)\n",
    "\n",
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Making predictions using the testing data\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "print(y_pred)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dc35c5-d55b-4deb-84ce-0934c13fef58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "# Print the balanced_accuracy score of the model\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc9456f-bd01-4b13-a1a7-1d03348ab84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a confusion matrix for the model\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1e1d80-1b4d-43b7-be48-78c65df104ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification report for the model\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5124924c-e3cd-4431-adf2-503bd45378ef",
   "metadata": {},
   "source": [
    "## Evaluation of ML model \n",
    "* wording here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8e45d1-a8a0-4921-a59c-5fc526e1c818",
   "metadata": {},
   "source": [
    "## Adding Sentimental Score and run ML again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7519e9-63cc-427c-a0a3-bbb58332b786",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run SentimentAnalysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dac8b8-a58c-46e0-8df1-f5b83c89ab69",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsla_sentiments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea2fb31-0c72-4be4-b170-a4af6dbb8100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift polarityScore down 1 row to make polarityScore from the previous day\n",
    "tsla_sentiments_df= tsla_sentiments_df.shift(1)\n",
    "tsla_sentiments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f2175b-16eb-4d5b-b863-773dc9effe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concated tsla_sentiments_df in to the main df\n",
    "df2= pd.concat([df,tsla_sentiments_df], axis=1)\n",
    "df2= df2.dropna()\n",
    "\n",
    "#Separate the y variable (the labels), and X variable (the features)\n",
    "y= df2['price_direction']\n",
    "X= df2.drop('price_direction', axis=1)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44949362-669d-4bb3-80d7-4e36f9d207ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun ML randomforest model on the new data set\n",
    "\n",
    "# Create train and test sets\n",
    "training_begin = X.index.min()\n",
    "training_end = X.index.min() + DateOffset(months=3)\n",
    "\n",
    "X_train = X.loc[training_begin:training_end]\n",
    "y_train = y.loc[training_begin:training_end]\n",
    "\n",
    "X_test = X.loc[training_end:]\n",
    "y_test = y.loc[training_end:]\n",
    "\n",
    "# Creating StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "# Fitting Standard Scaller\n",
    "X_scaler = scaler.fit(X_train)\n",
    "# Scaling data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Create a random forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=500, random_state=1)\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
    "y_pred = rf_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74add3cc-5af5-4827-8201-d1246c4ee3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification report for the model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d355c25-eadc-4caf-9d3d-751e3ae074e8",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "* improve recall for 1.0 prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178e8ea7-e8d1-4c49-b50a-042b5805f438",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store df2\n",
    "%store df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
