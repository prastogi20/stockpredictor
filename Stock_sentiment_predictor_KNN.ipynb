{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "823dc71e-df7b-459c-9acb-d8be71bb1eef",
   "metadata": {},
   "source": [
    "# Machine Learning model using K-nearest Neighbors algorithm\n",
    "\n",
    "## Created a Machine Learning model using KNeighborsClassifier for stock price direction prediction, optimisted the model and prepared analysis report. \n",
    "\n",
    "NOTE: Required data is stored in IPython's database\n",
    "\n",
    "1. Prepare training and test data\n",
    "2. Find the optimial value of n_neighbors for the dataset, using cross validation technique.\n",
    "3. Train model using the optimal number of neighbors\n",
    "4. Make predictions using trained model.\n",
    "5. Print classification report.\n",
    "\n",
    "Repeated above steps to optimise model, by varing parameters.\n",
    "\n",
    "**Scenario 1** Vary the maximum number of Neighbors e.g (21, 51) & performance score metric used for cross validation(e.g. \"accuracy\", \"recall\").   \n",
    "**Scenario 2** Keeping in mind time series nature of data by default training and testing data is prepared, also check the impact on performance of the model when train & test data is prepared using train_test_split.    \n",
    "**Scenario 3** Compare results by increasing/decreasing test data size.  \n",
    "**Scenario 4** Add sentiment analysis based on tweets as one of X feature to determine it's impact on performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b058cd8c-ace3-465e-9b93-1a0ea9b34e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report,balanced_accuracy_score\n",
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63a265c8-183a-4ab6-ad4a-ce61a3f2330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run PrepareData.ipynb\n",
    "# ta_df.plot(y=\"close_value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "115db60f-d3ab-4dc8-9dee-ea90b3674e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The purpose of this function is to prepare the training and test datasets\n",
    "def get_training_testing_data(dataframe,random=False,test_size=.25):\n",
    "    # we want to predict the direction of stock, so our target is price_direction\n",
    "    y = dataframe[\"price_direction\"]\n",
    "    print(y.value_counts())\n",
    "    \n",
    "    # dropping target from the features dataframe  \n",
    "    X = dataframe.drop([\"price_direction\"],axis=1)\n",
    "    \n",
    "    #  use test_train_split in case datasets are to be prepared randomly    \n",
    "    if(random):\n",
    "        # Split the dataset using train_test_split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=test_size,random_state=1)\n",
    "    else:\n",
    "        # Determine training and test data size on the basis on input value of test_size,\n",
    "        train_data_size = int (len(dataframe) * (1-test_size))\n",
    "        test_data_size = len(dataframe) - train_data_size\n",
    "        \n",
    "        # prepare training dataset, keeping in mind time series nature of the data.\n",
    "        train_start = X.index.min()\n",
    "        train_end = X.index.min() + pd.DateOffset(days=train_data_size)      \n",
    "        X_train = X.loc[train_start:train_end]\n",
    "        y_train = y.loc[train_start:train_end]\n",
    "        \n",
    "        # prepare test dataset, keeping in mind time series nature of the data.\n",
    "        test_start = train_end + pd.DateOffset(hours=1)         \n",
    "        X_test = X.loc[test_start:]\n",
    "        y_test = y.loc[test_start:]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test       \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "921057f5-9d21-4bcb-920e-6f8b2321e35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The purpose of this function is to get the optimal number of neighbors using cross validation technique\n",
    "def get_optimal_k_neighbors(maxnum,X_scaled_data,y_scaled_data,scoring=\"accuracy\"):\n",
    "    # checking for odd number of neighbors    \n",
    "    k_neighbors = [num for num in range(1,maxnum,2)]\n",
    "\n",
    "    k_acc_scores = []\n",
    "\n",
    "    for k in k_neighbors:\n",
    "        \n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        \n",
    "        # Compute cross validation scores, using accuracy/recall\n",
    "        cv_scores = cross_val_score(knn, X_scaled_data,y_scaled_data,cv=5, scoring=scoring)\n",
    "        \n",
    "        # Take the mean of scores and append to the list of scores        \n",
    "        k_acc_scores.append(cv_scores.mean())\n",
    "        \n",
    "        \n",
    "    # find optimal number of neighbors by finding the index of max score    \n",
    "    return k_neighbors[k_acc_scores.index(max(k_acc_scores))]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62daa774-8b15-4e43-bb99-99b94bacdab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function executes all steps required to develop, train and test KNN machine learning model depending \n",
    "# on the dataset and variable inputs, as an output it prints the classification report to analyse the performance of the model.\n",
    "def exe_knn_model(dataset,test_size=.25,max_neighbors=100,random_data=False,scoring=\"accuracy\"):  \n",
    "\n",
    "    X_train, X_test, y_train, y_test = get_training_testing_data(dataset,test_size=test_size,random=random_data)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fitting Standard Scaler\n",
    "    X_scaler = scaler.fit(X_train)\n",
    "\n",
    "    # Scaling data\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)\n",
    "    \n",
    "    # Get Optimal value of n_neighbors    \n",
    "    optimal_k_neighbors = get_optimal_k_neighbors(maxnum=max_neighbors,\n",
    "                                                  X_scaled_data=X_train_scaled,\n",
    "                                                  y_scaled_data=y_train,\n",
    "                                                  scoring=scoring)\n",
    "    \n",
    "    print(f\"Optimal value of n_neighbors is {optimal_k_neighbors}\")\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=optimal_k_neighbors)\n",
    "    \n",
    "    # Train model using training data\n",
    "    knn_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Create predictions using the testing data\n",
    "    y_pred = knn_model.predict(X_test_scaled)\n",
    "    \n",
    "    # Print the balanced_accuracy score of the model\n",
    "    print(f\"Balanced accuracy score for the model is {balanced_accuracy_score(y_test,y_pred)}\")\n",
    "    \n",
    "    # Print the classification report comparing the testing data to the model predictions\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18376c4b-7830-4e28-ba6f-d9aef309eed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For correct mapping with price_direction, get technical indicators of previous day\n",
    "ta_df_temp = ta_df.loc[:, ta_df.columns != 'price_direction'].shift(1)\n",
    "ta_df_temp['price_direction'] = ta_df['price_direction']\n",
    "ta_df_temp.dropna(inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c42a12-81f8-4434-ad38-eca86879660d",
   "metadata": {},
   "source": [
    "**Scenario 1** Vary the maximum number of Neighbors e.g (21, 51) & performance score metric used for cross validation(e.g. \"accuracy\", \"recall\").<br>  Based on these parameters evaluate the performance of the model. Find the optimal scoring technique to get optimal n_neighbors for improving performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a443dabb-d49b-4e38-92b3-3cf0547e9bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    676\n",
      "0    651\n",
      "Name: price_direction, dtype: int64\n",
      "Optimal value of n_neighbors is 5\n",
      "Balanced accuracy score for the model is 0.4778513412053784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.55      0.51       294\n",
      "           1       0.48      0.40      0.44       299\n",
      "\n",
      "    accuracy                           0.48       593\n",
      "   macro avg       0.48      0.48      0.47       593\n",
      "weighted avg       0.48      0.48      0.47       593\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Execute model where optimal value of n_neighbor cannot be more than 21, with 80% training data and 20% test data \n",
    "exe_knn_model(dataset=ta_df_temp,test_size=.2,max_neighbors=21,scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40cab5b0-3399-42fc-a613-a2ada227c706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal value of n_neighbors is 1\n",
      "Balanced accuracy score for the model is 0.5133665506336313\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.60      0.55       294\n",
      "           1       0.52      0.43      0.47       299\n",
      "\n",
      "    accuracy                           0.51       593\n",
      "   macro avg       0.51      0.51      0.51       593\n",
      "weighted avg       0.51      0.51      0.51       593\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exe_knn_model(dataset=ta_df_temp,test_size=.2,max_neighbors=21,scoring=\"recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd3cea23-64e9-453d-bd6e-dcbead43eb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal value of n_neighbors is 23\n",
      "Balanced accuracy score for the model is 0.4865765704275021\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.39      0.43       294\n",
      "           1       0.49      0.58      0.53       299\n",
      "\n",
      "    accuracy                           0.49       593\n",
      "   macro avg       0.49      0.49      0.48       593\n",
      "weighted avg       0.49      0.49      0.48       593\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exe_knn_model(dataset=ta_df_temp,test_size=.2,max_neighbors=51,scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1a38850-b107-4afc-8a6b-8d2107433ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal value of n_neighbors is 23\n",
      "Balanced accuracy score for the model is 0.4865765704275021\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.39      0.43       294\n",
      "           1       0.49      0.58      0.53       299\n",
      "\n",
      "    accuracy                           0.49       593\n",
      "   macro avg       0.49      0.49      0.48       593\n",
      "weighted avg       0.49      0.49      0.48       593\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exe_knn_model(dataset=ta_df_temp,test_size=.2,max_neighbors=201,scoring=\"recall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e05e52f-7cae-40ac-a6b4-3f8998582b49",
   "metadata": {},
   "source": [
    "**Scenario 2** Keeping in mind time series nature of data by default training and testing data is prepared, also check the impact if train & test data is prepared using train_test_split.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb8390bb-f44d-4e31-be99-2f229ad786c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal value of n_neighbors is 13\n",
      "Balanced accuracy score for the model is 0.46711607092278934\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.45      0.47       139\n",
      "           1       0.45      0.49      0.47       127\n",
      "\n",
      "    accuracy                           0.47       266\n",
      "   macro avg       0.47      0.47      0.47       266\n",
      "weighted avg       0.47      0.47      0.47       266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# as a result of our analysis in Scenario 1, the increase in number of neighbors is not improving the performance of the model, scoring technique recall gives better results.\n",
    "\n",
    "exe_knn_model(dataset=ta_df_temp,test_size=.2,random_data=True,max_neighbors=21,scoring=\"recall\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbd32e07-40b8-4d75-bbad-b2190ca68cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal value of n_neighbors is 69\n",
      "Balanced accuracy score for the model is 0.4946751260408996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.45      0.48       139\n",
      "           1       0.47      0.54      0.51       127\n",
      "\n",
      "    accuracy                           0.49       266\n",
      "   macro avg       0.49      0.49      0.49       266\n",
      "weighted avg       0.50      0.49      0.49       266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run test to see if Optimal value of n_neighbors changes when max_neighbors=101, \n",
    "\n",
    "exe_knn_model(dataset=ta_df_temp,test_size=.2,random_data=True,max_neighbors=101,scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b74589e-1c4b-4805-a64f-f66dabf614ef",
   "metadata": {},
   "source": [
    "**Scenario 3** Compare results by increasing/decreasing test data size.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e704fa7-1523-4484-a77e-93ae734047eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal value of n_neighbors is 5\n",
      "Balanced accuracy score for the model is 0.4916762857509298\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.54      0.51       339\n",
      "           1       0.50      0.44      0.47       345\n",
      "\n",
      "    accuracy                           0.49       684\n",
      "   macro avg       0.49      0.49      0.49       684\n",
      "weighted avg       0.49      0.49      0.49       684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#increase test data size\n",
    "exe_knn_model(dataset=ta_df_temp,test_size=.3,max_neighbors=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4055178-c08c-40df-ad0b-1a6264c3708c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal value of n_neighbors is 13\n",
      "Balanced accuracy score for the model is 0.5130605345410474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.52      0.51       244\n",
      "           1       0.53      0.51      0.52       257\n",
      "\n",
      "    accuracy                           0.51       501\n",
      "   macro avg       0.51      0.51      0.51       501\n",
      "weighted avg       0.51      0.51      0.51       501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#decrease test data size\n",
    "exe_knn_model(dataset=ta_df_temp,test_size=.1,max_neighbors=51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2263a5a0-c6f0-4a7d-9fcc-dc80ac9a0487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal value of n_neighbors is 13\n",
      "Balanced accuracy score for the model is 0.5130605345410474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.52      0.51       244\n",
      "           1       0.53      0.51      0.52       257\n",
      "\n",
      "    accuracy                           0.51       501\n",
      "   macro avg       0.51      0.51      0.51       501\n",
      "weighted avg       0.51      0.51      0.51       501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#decrease test data size\n",
    "exe_knn_model(dataset=ta_df_temp,test_size=.1,max_neighbors=51,scoring=\"recall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001504dd-dc6f-4c17-bd48-3e9a94c4a33e",
   "metadata": {},
   "source": [
    "**Scenario 4** Add sentiment analysis based on tweets as one of X feature to determine if it helps improve stock price direction prediction.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa836815-8ca6-4c6b-8fe6-1cfad05047d7",
   "metadata": {},
   "source": [
    "**Test including Vader sentiment analysis along with technical indicator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d8bc044-ef62-4737-b6ee-a6d8b5c19637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal value of n_neighbors is 15\n",
      "Balanced accuracy score for the model is 0.5037793952967525\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.47      0.49       235\n",
      "           1       0.50      0.54      0.52       228\n",
      "\n",
      "    accuracy                           0.50       463\n",
      "   macro avg       0.50      0.50      0.50       463\n",
      "weighted avg       0.50      0.50      0.50       463\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Added VaderSentiments to the features along with technical indicators\n",
    "ta_df_vader_temp = pd.concat([ta_df_temp,tsla_sentiments_df],axis=1, join=\"inner\")\n",
    "\n",
    "exe_knn_model(dataset=ta_df_vader_temp,test_size=.1,max_neighbors=21,scoring=\"recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "126a7dd7-3ac4-41dc-bd46-4e28b82e5901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal value of n_neighbors is 21\n",
      "Balanced accuracy score for the model is 0.4995893990294886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.46      0.48       235\n",
      "           1       0.49      0.54      0.52       228\n",
      "\n",
      "    accuracy                           0.50       463\n",
      "   macro avg       0.50      0.50      0.50       463\n",
      "weighted avg       0.50      0.50      0.50       463\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking to see if increase in n_neighbors improves the results\n",
    "exe_knn_model(dataset=ta_df_vader_temp,test_size=.1,max_neighbors=201,scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f90919a-6d16-4ffc-a6f6-0263fd81d9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal value of n_neighbors is 63\n",
      "Balanced accuracy score for the model is 0.5057417565856893\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.48      0.50       318\n",
      "           1       0.50      0.53      0.52       313\n",
      "\n",
      "    accuracy                           0.51       631\n",
      "   macro avg       0.51      0.51      0.51       631\n",
      "weighted avg       0.51      0.51      0.51       631\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# As there is a slight improvement in when n_neighbors increases, checking if further increase in number of neighbors imporves the result\n",
    "exe_knn_model(dataset=ta_df_vader_temp,test_size=.3,max_neighbors=201)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33356be8-1075-498a-90ac-d99f2fcf1355",
   "metadata": {},
   "source": [
    "**Test including TextBolb sentiment analysis along with technical indicator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78155fe9-0485-4cf0-aaa1-4843b4edc278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal value of n_neighbors is 1\n",
      "Balanced accuracy score for the model is 0.5039049919484702\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.48      0.50       276\n",
      "           1       0.50      0.53      0.51       270\n",
      "\n",
      "    accuracy                           0.50       546\n",
      "   macro avg       0.50      0.50      0.50       546\n",
      "weighted avg       0.50      0.50      0.50       546\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Added Textblob subjectivity and polarity to the features along with technical indicators\n",
    "ta_df_text_blob_temp = pd.concat([ta_df_temp,tsla_sentiments_df_textblob],axis=1, join=\"inner\")\n",
    "\n",
    "exe_knn_model(dataset=ta_df_text_blob_temp,test_size=.2,max_neighbors=21,scoring=\"recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "494b6352-5689-4e58-abe7-a0355eb41eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal value of n_neighbors is 41\n",
      "Balanced accuracy score for the model is 0.49991948470209335\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.34      0.41       276\n",
      "           1       0.49      0.66      0.57       270\n",
      "\n",
      "    accuracy                           0.50       546\n",
      "   macro avg       0.50      0.50      0.49       546\n",
      "weighted avg       0.50      0.50      0.49       546\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exe_knn_model(dataset=ta_df_text_blob_temp,test_size=.2,max_neighbors=51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "459eaeb0-7ad4-413d-a339-e0bf20dcf81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal value of n_neighbors is 97\n",
      "Balanced accuracy score for the model is 0.4674633793477606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.27      0.34       318\n",
      "           1       0.47      0.66      0.55       313\n",
      "\n",
      "    accuracy                           0.47       631\n",
      "   macro avg       0.46      0.47      0.45       631\n",
      "weighted avg       0.46      0.47      0.45       631\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exe_knn_model(dataset=ta_df_text_blob_temp,test_size=.3,max_neighbors=101,scoring=\"recall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15800c6-6f19-455b-9e7b-57d20e087ab6",
   "metadata": {},
   "source": [
    "# KNN Analysis\n",
    "## Summary\n",
    "We tired different premutations and combinations of parameters to optimise our KNN model,by finding the optimal value of n_neighbors for parameters used to train and test the model.\n",
    "Also we evaluated the model by including sentiment analysis based on tweets data along with other features.\n",
    "\n",
    "If we take the best case scenario from among all tests we did, model predicted with overall accuracy of 51.3%. The model predicted 52% of true negative and 51% of true positive for stock price direction. Below is the classification report for best performing model from among all knn models we created.</br>\n",
    "\n",
    ">Optimal value of n_neighbors is 13<br>\n",
    ">Balanced accuracy score for the model is 0.5130605345410474<br>\n",
    ">\n",
    ">                   precision    recall  f1-score   support\n",
    ">\n",
    ">                0       0.50      0.52      0.51       244\n",
    ">                1       0.53      0.51      0.52       257\n",
    ">\n",
    ">         accuracy                           0.51       501\n",
    ">        macro avg       0.51      0.51      0.51       501\n",
    ">     weighted avg       0.51      0.51      0.51       501\n",
    "\n",
    "\n",
    "## Details\n",
    "### Scenario 1\n",
    "Impact of scoring technique used to find n_neighbors on performance of the KNN Model\n",
    "\n",
    "**Given the data it is observed that performace of KNN model improves, when n_neighbors is set to 1 and test size is 20%. The optimal value of n_neighbors is obtained by using cross validation scoring technique using \"recall\" score.</br>**\n",
    "\n",
    "***Below are the results when optimal value of n_neighbors is obtained by using cross_val_score, with scoring set to \"recall\"***  \n",
    ">Optimal value of n_neighbors is 1<br>\n",
    ">Balanced accuracy score for the model is 0.5133665506336313<br>\n",
    ">\n",
    ">                   precision    recall  f1-score   support \n",
    ">\n",
    ">                0       0.51      0.60      0.55       294  \n",
    ">                1       0.52      0.43      0.47       299   \n",
    ">\n",
    ">         accuracy                           0.51       593 \n",
    ">        macro avg       0.51      0.51      0.51       593  \n",
    ">     weighted avg       0.51      0.51      0.51       593  \n",
    "\n",
    "***Below are the results when optimal value of n_neighbors is obtained by using cross_val_score, with scoring set to \"accuracy\"***  \n",
    ">Optimal value of n_neighbors is 5<br>                                 \n",
    ">Balanced accuracy score for the model is 0.4778513412053784<br>\n",
    ">\n",
    ">                   precision    recall  f1-score   support             \n",
    ">\n",
    ">                0       0.48      0.55      0.51       294  \n",
    ">                1       0.48      0.40      0.44       299  \n",
    ">\n",
    ">         accuracy                           0.48       593  \n",
    ">        macro avg       0.48      0.48      0.47       593  \n",
    ">     weighted avg       0.48      0.48      0.47       593  \n",
    "\n",
    "### Scenario 2\n",
    "Impact of the way training and testing dataset are generated on performance of the KNN Model.\n",
    "\n",
    "**Given the data it is observed that KNN Model perform better when training & testing datasets are constructed keeping time series nature of the data in mind, which is also the default behaviour of the KNN Model we created. It is observed that when training & testing datasets randomly using train_test_split the performance of our model falls.<br>**\n",
    "\n",
    "***Referring to the classification report below,these are the best results that we could achieve when training and testing datasets are generated randomly.***  \n",
    ">Optimal value of n_neighbors is 69<br>\n",
    ">Balanced accuracy score for the model is 0.4946751260408996<br>\n",
    ">\n",
    ">                   precision    recall  f1-score   support\n",
    ">    \n",
    ">                0       0.52      0.45      0.48       139\n",
    ">                1       0.47      0.54      0.51       127\n",
    ">    \n",
    ">         accuracy                           0.49       266\n",
    ">        macro avg       0.49      0.49      0.49       266\n",
    ">     weighted avg       0.50      0.49      0.49       266\n",
    "\n",
    "### Scenario 3\n",
    "Impact of increasing/decreasing test data size on performance of the model.\n",
    "\n",
    "**As there is a major peak in data on later dates, increasing the training dataset & reducing test data size to 10% from 20% improved the performance of the model***\n",
    "\n",
    "***Referring to the classification report below,these are the best results that we could achieve by increasing the training dataset to 90%.***  \n",
    ">Optimal value of n_neighbors is 13<br>\n",
    ">Balanced accuracy score for the model is 0.5130605345410474<br>\n",
    ">\n",
    ">                   precision    recall  f1-score   support\n",
    ">\n",
    ">                0       0.50      0.52      0.51       244\n",
    ">                1       0.53      0.51      0.52       257\n",
    ">\n",
    ">         accuracy                           0.51       501\n",
    ">        macro avg       0.51      0.51      0.51       501\n",
    ">     weighted avg       0.51      0.51      0.51       501\n",
    "\n",
    "\n",
    "### Scenario 4\n",
    "\n",
    "Impact of adding results of Sentiments analysis based on the tweets along with technical indicators, on the performance of the model.\n",
    "\n",
    "**Our model performed slightly better with the output received from VaderSentiment analysis, also we observed that VaderSentiment analysis is much faster than Textblob**\n",
    "\n",
    "#### Using VaderSentiment Analysis\n",
    "\n",
    "***When we added polarity of sentiments as one of the feature along with technical indicators, below is the best performance we could achieve. In this scenario increasing the test data size to 30% helped improve the performance of the model***\n",
    "\n",
    "\n",
    ">Optimal value of n_neighbors is 63<br>\n",
    ">Balanced accuracy score for the model is 0.5057417565856893<br>\n",
    ">\n",
    ">                   precision    recall  f1-score   support\n",
    ">\n",
    ">                0       0.51      0.48      0.50       318\n",
    ">                1       0.50      0.53      0.52       313\n",
    ">\n",
    ">         accuracy                           0.51       631\n",
    ">        macro avg       0.51      0.51      0.51       631\n",
    ">     weighted avg       0.51      0.51      0.51       631\n",
    "\n",
    "#### Using TextBlob Sentiment Analysis\n",
    "\n",
    "***When we added output received from TextBlob sentiment analysis as one of the feature along with technical indicators, below is the best performance we could achieve. In this scenario the test data size of 20% helped improve the performance of the model***\n",
    "\n",
    ">Optimal value of n_neighbors is 1<br>\n",
    ">Balanced accuracy score for the model is 0.5039049919484702<br>\n",
    ">\n",
    ">                   precision    recall  f1-score   support\n",
    ">     \n",
    ">                0       0.51      0.48      0.50       276\n",
    ">                1       0.50      0.53      0.51       270\n",
    ">     \n",
    ">         accuracy                           0.50       546\n",
    ">        macro avg       0.50      0.50      0.50       546\n",
    ">     weighted avg       0.50      0.50      0.50       546\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512e447e-1db5-494c-a5c5-c32bff10f5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
